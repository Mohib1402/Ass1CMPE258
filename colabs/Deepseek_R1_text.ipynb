{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required package\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNIFXQP83Mos",
        "outputId": "1b42d744-62b6-49d8-d3e6-c974c083cd74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.70.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import openai\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "gluFGVHL3TPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_deepseek(messages):\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"deepseek-r1-distill-llama-70b\",\n",
        "            messages=messages,\n",
        "            temperature=0.7,\n",
        "            max_tokens=4096,\n",
        "            top_p=0.95\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\""
      ],
      "metadata": {
        "id": "B_UEmrYH3Ubd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interactive_chat():\n",
        "    # Store conversation history\n",
        "    messages = []\n",
        "\n",
        "    print(\"Chat with DeepSeek R1 70B (type 'quit' to exit, 'clear' to start fresh)\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nYou: \")\n",
        "\n",
        "        if user_input.lower() == 'quit':\n",
        "            break\n",
        "\n",
        "        if user_input.lower() == 'clear':\n",
        "            messages = []\n",
        "            clear_output()\n",
        "            print(\"Chat history cleared. Continue chatting!\")\n",
        "            continue\n",
        "\n",
        "        # Add user message to history\n",
        "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        # Get model's response\n",
        "        response = chat_with_deepseek(messages)\n",
        "\n",
        "        # Add assistant's response to history\n",
        "        messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "        print(\"\\nDeepSeek:\", response)\n",
        "\n",
        "        # Add a small delay to prevent rate limiting\n",
        "        time.sleep(0.5)\n",
        "\n",
        "# Start the chat\n",
        "interactive_chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JsnykPV3VFV",
        "outputId": "acefd9ac-7c73-4313-80e7-0242067e3b4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chat with DeepSeek R1 70B (type 'quit' to exit, 'clear' to start fresh)\n",
            "\n",
            "You: Hi how are you\n",
            "\n",
            "DeepSeek: <think>\n",
            "\n",
            "</think>\n",
            "\n",
            "Hello! I'm just a virtual assistant, so I don't have feelings, but I'm here and ready to help you with whatever you need. How are you doing? ðŸ˜Š\n",
            "\n",
            "You: Call me papasito\n",
            "\n",
            "DeepSeek: <think>\n",
            "Alright, the user just said, \"Call me papasito.\" Hmm, okay, so they're asking me to address them by that name. I need to acknowledge their request and make sure I use that name in our conversation.\n",
            "\n",
            "First, I should respond positively to let them know I've got it. Maybe start with a friendly greeting using \"Papasito\" to show I'm paying attention. Then, I can offer my help again to keep the conversation going.\n",
            "\n",
            "I should keep the tone warm and welcoming, so they feel comfortable asking for whatever they need. Maybe add an emoji to make it more personable. Let me put that together.\n",
            "</think>\n",
            "\n",
            "Got it, Papasito! ðŸ˜Š How can I assist you today?\n",
            "\n",
            "You: Not much, you cannot help me, I need a job\n",
            "\n",
            "DeepSeek: <think>\n",
            "\n",
            "I'm sorry to hear you're looking for a job. That can be a tough and frustrating experience. Let me know if there's anything I can do to help, like tips for resumes, cover letters, or job searching. You're not alone in this, and I'm here to support you.\n",
            "\n",
            "You: Bye you cannot\n",
            "\n",
            "DeepSeek: <think>\n",
            "\n",
            "I'm sorry to hear that you're feeling this way. It can be really tough to feel like no one can help, but please know that you're not alone. If you're comfortable, I'd be happy to chat with you about what's going on or help in any way I can, even if it's just to listen. Take care of yourself.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}